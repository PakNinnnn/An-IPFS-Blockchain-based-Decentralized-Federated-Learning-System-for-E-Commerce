import base64
import torch
import io

base64_encoded_model = "UEsDBAAACAgAAAAAAAAAAAAAAAAAAAAAAAAQABIAYXJjaGl2ZS9kYXRhLnBrbEZCDgBaWlpaWlpaWlpaWlpaWoACY2NvbGxlY3Rpb25zCk9yZGVyZWREaWN0CnEAKVJxAShYCQAAAGZjLndlaWdodHECY3RvcmNoLl91dGlscwpfcmVidWlsZF90ZW5zb3JfdjIKcQMoKFgHAAAAc3RvcmFnZXEEY3RvcmNoCkZsb2F0U3RvcmFnZQpxBVgBAAAAMHEGWAMAAABjcHVxB0sKdHEIUUsASwFLCoZxCUsKSwGGcQqJaAApUnELdHEMUnENWAcAAABmYy5iaWFzcQ5oAygoaARoBVgBAAAAMXEPaAdLAXRxEFFLAEsBhXERSwGFcRKJaAApUnETdHEUUnEVdX1xFlgJAAAAX21ldGFkYXRhcRdoAClScRgoWAAAAABxGX1xGlgHAAAAdmVyc2lvbnEbSwFzWAIAAABmY3EcfXEdaBtLAXN1c2IuUEsHCLgNEJ06AQAAOgEAAFBLAwQAAAgIAAAAAAAAAAAAAAAAAAAAAAAADgAKAGFyY2hpdmUvZGF0YS8wRkIGAFpaWlpaWlW7RL4yIk++csHGPQ0Ktbv6hms+mXODvn1Uhr7XmWE+zOrcPZrsTD5QSwcI5F739igAAAAoAAAAUEsDBAAACAgAAAAAAAAAAAAAAAAAAAAAAAAOABwAYXJjaGl2ZS9kYXRhLzFGQhgAWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpasE2VvlBLBwjBb5tkBAAAAAQAAABQSwMEAAAICAAAAAAAAAAAAAAAAAAAAAAAAA8APwBhcmNoaXZlL3ZlcnNpb25GQjsAWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlpaWlozClBLBwjRnmdVAgAAAAIAAABQSwECAAAAAAgIAAAAAAAAuA0QnToBAAA6AQAAEAAAAAAAAAAAAAAAAAAAAAAAYXJjaGl2ZS9kYXRhLnBrbFBLAQIAAAAACAgAAAAAAADkXvf2KAAAACgAAAAOAAAAAAAAAAAAAAAAAIoBAABhcmNoaXZlL2RhdGEvMFBLAQIAAAAACAgAAAAAAADBb5tkBAAAAAQAAAAOAAAAAAAAAAAAAAAAAPgBAABhcmNoaXZlL2RhdGEvMVBLAQIAAAAACAgAAAAAAADRnmdVAgAAAAIAAAAPAAAAAAAAAAAAAAAAAFQCAABhcmNoaXZlL3ZlcnNpb25QSwYGLAAAAAAAAAAeAy0AAAAAAAAAAAAEAAAAAAAAAAQAAAAAAAAA8wAAAAAAAADSAgAAAAAAAFBLBgcAAAAAxQMAAAAAAAABAAAAUEsFBgAAAAAEAAQA8wAAANICAAAAAA=="

# Step 1: Decode the Base64 string into binary data
model_binary = base64.b64decode(base64_encoded_model)

# Step 2: Use an in-memory buffer to load the binary data
buffer = io.BytesIO(model_binary)

# Step 3: Load the PyTorch model
model = torch.load(buffer)

print("Model successfully loaded!")